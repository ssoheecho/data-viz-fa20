Read full documentation on the assignment [here](https://www.notion.so/midterm-5d51bb3046dc44078ac1cd57e17e3bf8)

### Scenario:

A museum is planning an exhibition on gender. They have not quite framed the exhibition yet, and are looking at you, the creative director, to handle that. In addition, it is your job to come up with three installation ideas that clearly fall within your chosen theme and clearly visualize the data in your sources. Don't limit yourself by thinking of a kiosk type interaction. Dream big!

**Your concepts should include:**

- **a description or user flow of the experience**
- **images of the installation at large**
- **a focus view on the visualization**

Included with these concepts will be a **Title for the exhibit** and **a description of the exhibit theme**.

### Project:

*Exhibition Title:*
**man : computer programmer = woman : homemaker?**

*Floorplan:* 
![floorplan](/assets/floorplan.png)

*General Wall Text:*

More than ever, technology dominates our reality. We have come to believe that technology is the key to a democratic space of information. However, over the past few years, we have seen that more often than not information is skewed, obscured, and prejudiced in our digital space. Humans are inherently biased and thus our creations inherit those biases.

This exhibition specifically focuses on gender bias embedded in natural language processing — a field of study in Artificial Intelligence concerned with how computers process the human language.

Because natural language algorithms that are used to train neural networks are trained on datasets derived from our digital space, they manifest and also amplify gender stereotypes that exist in our language. The first installation investigates a language model that is trained on comments aggregated from Wikipedia. The model is used to map out the relationship between different occupations and the words “man” and “woman”. The second installation explores a predictive neural network that generates text content based on input that include gendered words. The third installation prompts the machine to analyze our gender based on the way we write about a given prompt.

As technology advances, it is crucial we understand the systematic inequality that govern our digital existence.

*Installation 1:*

Here we explore a vector embedding model called GloVe. Because computers cannot understand the human language as is, words and phrases are mapped to vectors of real numbers. Using these vectors, computers can then form relationships between different words and determine how similar some words are based on the calculated distances.

We took the words “man” and “woman” and mapped them in relation to occupation titles. Visitors can touch the circles on the screen table representing the different occupations to see the represented distance on the wall. Whenever an occupation is selected, a search algorithm is prompted on the screen table and the visitors are presented with the top image results corresponding to the occupation in question.

*Installation 2:*

Predictive language models have become so powerful that it has become difficult to tell human and computer writing apart. However, computers impose fixed contexts they learn from datasets that may require much further reading. Here we prompt the computers to finish short narratives that start with the phrases, “I am a woman.” and “I am a man.” We ask the visitors to identify which narratives are connected to each prompt.

*Installation 3:*

In this participatory exercise, we ask our visitors to ask the computer to correctly guess our gender based on how they write. Visitors may keep the printed results or add them to the wall. If the computer guessed to your agreement, put a yellow sticker, if not, put a red sticker.

![installation general view](/assets/installation_01.png)
![installation 01 mockup](/assets/installation_02.png)
![installation 01 mockup](/assets/installation_03.png)
![installation 02 mockup](/assets/installation_04.png)
![installation 03 mockup](/assets/installation_05.png)

